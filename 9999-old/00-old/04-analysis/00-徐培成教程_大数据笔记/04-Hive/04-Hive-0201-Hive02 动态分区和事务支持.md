## 1，Hive的使用02

* select * from TBLS \G;  😁\G是行转列，在查看的时候比较方便一些，技能+1；

### 01，自动分区(动态分区)：
  *在加入的时候根据加入数据的字段自动分区，而不必把分区数据定死。如下，演示一下动态分区*

  * 首先创建一个有年份和月份的表，用作数据插入的元数据
    
```mysql
create table t7 (id int , name string , age int, year string, month string);
```



  * 然后插入两条不同年份或月份的数据吧
    
```mysql
insert into t7 (id, name, age, year, month) values (1, "ivanl0000", 10, 2015, 12);

insert into t7 (id, name, age, year, month) values (2, "ivanl111111", 15, 2016, 11);
```



  * 然后把上面表中的两条数据插入到我们之前建的分区表t5中去，因为并没有开启动态分区，会报错：
    
```mysql
insert into t5 partition (year, month) select id, name, age, year, month from t7;
```



  * 上面的插入会报错, 默认严格模式，严格模式在插入时候必须要指定一个静态分区，我们关闭这个严格模式即可：
    
```java
FAILED: SemanticException [Error 10096]: Dynamic partition strict mode requires at least one static partition column. To turn this off set hive.exec.dynamic.partition.mode=nonstrict
```



  * 根据提示可以知道需要设置分区模式为非严格模式
    
```mysql
set hive.exec.dynamic.partition.mode=nonstrict
```



  * 重新插入发现ok了

  

### 02，hive的事务

*只有用事务才能支持行级操作，比如更新，删除某一行等等*

  * 使用事务必须要先配置如下：
    ```properties
    1.所有事务自动提交。
    2.只支持orc格式。
    3.使用bucket表。 
    4.配置hive参数，使其支持事务。
    ```

###### 注意：下面如果只是在命令行设置而不改变配置文件，那么只会单次有效哈

```mysql
SET hive.support.concurrency = true;				
SET hive.enforce.bucketing = true;
# 上面会报错Query returned non-zero code: 1, cause: hive configuration hive.enforce.bucketing does not exists.，先忽略
SET hive.exec.dynamic.partition.mode = nonstrict;	
SET hive.txn.manager = org.apache.hadoop.hive.ql.lockmgr.DbTxnManager;
SET hive.compactor.initiator.on = true;
SET hive.compactor.worker.threads = 1;
```

  * 显示当前运行的事务
    
```mysql
show transactions;
```



* 更新操作(默认使用事务自动提交)

```shell
update t2 set name = 'ivanl001' where id = 2;

# 其实会报错：FAILED: SemanticException [Error 10297]: Attempt to do update or delete on table imdb.t2 that does not use an AcidOutputFormat or is not bucketed， 因为表不是桶表
```



  * 所以我们这里需要重新建立一个桶表,但是跟之前不一样，这里需要额外设置存储格式为orc
    
```mysql
create table t8 (id int, name string, age int) clustered by (id) into 3 buckets row format delimited fields terminated by ',' stored as orc;
```



  * 因为load是没办法完成分桶操作的， 所以还是和之前一样， 直接从t5表中拷贝过来
    
```mysql
insert into t8 select id, name, age from t5;
```



* 执行更新操作

```mysql
update t8 set name = "ivanl001" where id = 3;

# 不过还是会报错： FAILED: SemanticException [Error 10122]: Bucketized tables do not support INSERT INTO: Table: imdb.t8
# 最后发现是有一个属性需要在创建表的时候指定，所以我们重新创建表t9, 具体属性如下
```



  * 重新创建新表t9:需要设置属性TBLPROPERTIES, 注意：单词别写错了，吃过亏
    
```mysql
create table t9 (id int, name string, age int) clustered by (id) into 3 buckets row format delimited fields terminated by ',' stored as orc tblproperties  ('transactional'='true');
```



  * 然后重新把数据拷贝过来
    
```mysql
insert into t9 select id, name, age from t5;
```



  * 执行更新操作
    
```mysql
update t9 set name = "ivanl001" where id = 3;
```



  * 这次就ok啦。嘿嘿😁



## 03，group by

> group by 是可以去重的，在元聚的时候经常这么用，大家应该都是这么用的

*注意：分组聚合的话，select的信息只能是组的信息，而不能是每一条的信息了， 比如说按照用户分组，那么能查出来的肯定是这个用户的比如说订单数量， 订单总金额等等，而不能是具体订单等信息*

```mysql
select id, name, price , cid from orders group by cid;
# 所以这个会直接报错：FAILED: SemanticException [Error 10025]: Line 1:7 Expression not in GROUP BY key 'id'
# 这样是可以的
select count(*), sum(price), cid from orders group by cid;
# 分组之后再进行条件筛选
select count(*), sum(price) as s, cid from orders group by cid having cid > 30;

```

