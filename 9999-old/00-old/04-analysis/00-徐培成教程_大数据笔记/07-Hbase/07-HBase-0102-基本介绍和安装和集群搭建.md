## 1, Hbase的介绍

* hadoop数据库，分布式可伸缩大型数据存储。
* 用户对随机、实时读写数据。
* 十亿行 x 百万列。
* 版本化、非关系型数据库。
* 存储机制：面向列存储，table是按row排序。

* ![IMAGE](https://learningnotebookv1-1302566743.cos.ap-nanjing.myqcloud.com/img/CB8485F4F5783DBE1CD17CF7650FF13F.jpg)



## 2，Hbase集群搭建

### 01, 选择服务器

和hdfs类似，HBase分主节点和区域节点,我们这里选择master和master01作为主节点，slave01, slave02, slave03作为区域节点



### 02, 下载解压

下载解压配置环境变量这里就不再赘述



### 03, 版本验证

```shell
hbase version
```



### 04, 配置hbase的模式

#### 0401, 本地模式

就是配置一下hbase的本地存储目录就好了

```shell
# hbase-env.sh中修改jkd的路径
EXPORT JAVA_HOME=/usr/local/jdk
```


```xml
<!--hbase-site.xml指定文件存储路径-->
<property>
	<name>hbase.rootdir</name>
	<value>file://data/HBase/HFiles</value>
</property>
```

#### 0402, 伪分布模式

```shell
# hbase-env.sh中修改jkd的路径
EXPORT JAVA_HOME=/usr/local/jdk
```

```xml
<!--hbase-site.xml开启分布式并指定文件存储路径-->
# hbase-site.xml
<property>
	<name>hbase.cluster.distributed</name>
	<value>true</value>
</property>
<property>
	<name>hbase.rootdir</name>
	<value>hdfs://localhost:8030/hbase</value>
</property>
```

#### 0403, 完全分布式


```shell
# hbase-env.sh中修改jkd的路径
export JAVA_HOME=/usr/local/jdk

# hbase默认有自己的zk，这里应该是不用hbase自己的zk，而是用我们部署的那个zk
export HBASE_MANAGES_ZK=false
```

```xml
<!--hbase-site.xml开启分布式并指定文件存储路径-->
# hbase-site.xml
<property>
  <name>hbase.cluster.distributed</name>
  <value>true</value>
</property>
<!--指定hbase数据在hdfs上的存放路径-->
<property>
  <name>hbase.rootdir</name>
  <!--这里填写的是你想要的主服务器的地址，不能是集群nn的-->
  <value>hdfs://master:8020/hbase</value>
</property>
<!-- 配置zk地址 -->
<property>
  <name>hbase.zookeeper.quorum</name>
  <value>slave01:2181,slave02:2181,slave03:2181</value>
</property>
<!-- zk的本地目录 -->
<property>
  <name>hbase.zookeeper.property.dataDir</name>
  <value>/data/zookeeper</value>
</property>
```

  *同时需要在config目录下的regionservers中添加hbase的数据服务器*
```java
slave01
slave02
slave03
```

  *如果需要备用的主服务器，需要在regionservers相同的目录下，添加文件:backup-masters*
```java
master01
```

### 05, 启动hbase

* 最好在主服务器上启动

```shell
start-hbase.sh
```



### 06, 页面验证

* http://master:16010





## 3, HBase与hdfs集群的融合

*我们hdfs是需要结合zk进行容灾处理的， 比如我们的这个，有master和master01两台namenode的服务器， 任何一台挂掉，另外一台就必须从standby变为active活跃节点，那按照我们上面的hbase的集群是不能和这种集群hdfs完美的工作在一起的，因为我们已经指定了hbase.rootdir为master了，如果hdfs容灾之后， 这种设置就会让hbase出现问题，下面的配置可以让我们实现和容灾的hdfs的融合*

* 01, 这里设置集群的nn，和上面的配置相比，其实只需改动hbase.rootdir
  ```xml
  <!--hbase-site.xml开启分布式并指定文件存储路径-->
  # hbase-site.xml
  <property>
      <name>hbase.cluster.distributed</name>
      <value>true</value>
  </property>
  <!--指定hbase数据在hdfs上的存放路径-->
  <property>
      <name>hbase.rootdir</name>
      <!--这里填写的是集群nn的-->
      <value>hdfs://imcluster:8020/hbase</value>
  </property>
      <!-- 配置zk地址 -->
  <property>
      <name>hbase.zookeeper.quorum</name>
      <value>slave01:2181,slave02:2181,slave03:2181</value>
  </property>
  <!-- zk的本地目录 -->
  <property>
      <name>hbase.zookeeper.property.dataDir</name>
      <value>/data/zookeeper</value>
  </property>
  ```
  
* 02，在hbase的根目录下创建一个hadoop的配置文件hdfs-site.xml的软连接，这里大家的具体命令可能不太一样，根据具体情况而定

  > imcall.sh ln -s /usr/local/hadoop-2.7.5/etc/hadoop/hdfs-site.xml /usr/local/hbase-2.1.0/conf/hdfs-site.xml

