#### 1, spark, storm, flink比较

| 比较项   | storm                | storm-trident       | spark                                      | flink                                    |
| :------- | -------------------- | ------------------- | ------------------------------------------ | ---------------------------------------- |
| 运行模型 | Native(单条立即处理) | micro-batching      | micro-batching                             | Native(单条立即处理)                     |
| API      | 组合(会用到底层api)  | 组合(会用到底层api) | 声明式(高级api)                            | 声明式                                   |
|          | 也就是自己实现       | 也就是自己实现      | map, reduce                                | map,reduct等                             |
|          |                      |                     |                                            |                                          |
| 保证次数 | at-least-once        | exectly-once        | exectly-once(spark需要自己提交kafka偏移量) | exectly-once(官方在sink中提交，保证一次) |
|          |                      |                     |                                            |                                          |
| 容错     | Record ack           | Record ack          | RDD checkpoint                             | checkpoint                               |
| 状态管理 | 无                   | 基于操作            | 基于DStream                                | 基于操作                                 |
|          |                      |                     |                                            |                                          |
| 延时性   | 低                   | 中等                | 中等                                       | 低                                       |
| 吞吐量   | 低                   | 中等                | 高                                         | 高                                       |

​	

#### 2, Streamingx和batch比较

##### 2.1, Streaming

* StreamExecutionEnvironment
* 返回值是DataStream

```scala
//获取流处理环境
val env: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment

val text = env.readTextFile("/Users/ivanl001/Desktop/bigData/00-data/input/ivanl001.txt")

//返回值是DataStream
//5s一个窗口，1s滚动一次, 注意：这里的flatMap其实就是flat，并没有map, 所以最后还需要map一下
val windowCounts = text
.flatMap ({ w => w.split("\\s") })
.map { w => WordWithCount(w, 1) }
.keyBy("word")
.timeWindow(Time.minutes(10), Time.seconds(1))
.sum("count")

windowCounts.print().setParallelism(1)

env.execute("Socket Window WordCount")
```

##### 2.2, batch

- ExecutionEnvironment
- 返回值是DataSet

```scala
//获取批处理环境
val env = ExecutionEnvironment.getExecutionEnvironment

val text = env.readTextFile("/Users/ivanl001/Desktop/bigData/00-data/input/ivanl001.txt")

//返回值是：DataSet
val dataset = text
.flatMap({w => w.split("\\s")})
.map({w => (w, 1)})
.groupBy(0)
.sum(1)

dataset.print()

env.execute("wordcount_batch_scala")
```

