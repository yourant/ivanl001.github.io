#### 1，自定义转换函数，以map举例

##### 1.1， 继承map

##### 1.2， 继承richmap

##### 1.3， 使用lamda函数



#### 2，flink支持的数据类型

一共7种：

2.1, java的Tuple和scala的Case类

* java的元组，Tuple1-Tuple25，
* scala：case class WordCount(word:String, count: Int)

2.2, java的POJO

* plain old Java object， java对象， 没有继承其他，最简单的java类

2.3, 基本类型

* java和scala的基本数据类型, Integer, String等

2.4, 通用类或者一般类

* java类和scala类

2.5, 值



2.6, Hadoop 的Writables



2.7, 特殊类型

* 不常用的







#### 3,  计数器和累加器

https://ci.apache.org/projects/flink/flink-docs-release-1.7/dev/api_concepts.html#accumulators--counters

![image-20190517141047616](../../03-%E5%A4%A7%E6%95%B0%E6%8D%AE%E8%87%AA%E5%AD%A6v2.0/05-Flink/assets/image-20190517141047616.png)

##### 3.1, 使用累加器

- 第一步:在自定义的转换操作里创建累加器对象: 

  > private IntCounter numLines = new IntCounter(); 

- 第二步:注册累加器对象，通常是在rich function的open()方法中。这里你还需要定义累加器的名字 >

  > getRuntimeContext().addAccumulator(“num-lines”, this.numLines); 

- 第三步:在operator函数的任何地方使用累加器，包括在open()和close()方法中 

  > this.numLines.add(1); 

- 第四步:结果存储在JobExecutionResult里:

  > JobExecutionResult JobExecutionResult =env.execute("Flink Batch Java API Skeleton") myJobExecutionResult.getAccumulatorResult("num-lines") 

```java
package im.ivanl001.a01_flink_batch_simple_java;

import org.apache.flink.api.common.JobExecutionResult;
import org.apache.flink.api.common.accumulators.IntCounter;
import org.apache.flink.api.common.functions.FlatMapFunction;
import org.apache.flink.api.common.functions.ReduceFunction;
import org.apache.flink.api.common.functions.RichFlatMapFunction;
import org.apache.flink.api.java.DataSet;
import org.apache.flink.api.java.ExecutionEnvironment;
import org.apache.flink.api.java.operators.AggregateOperator;
import org.apache.flink.api.java.operators.DataSource;
import org.apache.flink.api.java.operators.UnsortedGrouping;
import org.apache.flink.configuration.Configuration;
import org.apache.flink.util.Collector;

/**
 * #author      : ivanl001
 * #creator     : 2019-05-13 16:57
 * #description : java的批处理的wordcount, 这里顺便演示一下累加器的使用
 **/
public class Flink_batch_simple_java {
    public static void main(String[] args) throws Exception {
        ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();
        DataSource<String> text = env.readTextFile("/Users/ivanl001/Desktop/bigData/00-data/input/ivanl001.txt");
        DataSet<WordWithCount> wordCounts = text
                .flatMap(new RichFlatMapFunction<String, WordWithCount>() {
                    private IntCounter numLines = new IntCounter();
                    @Override
                    public void open(Configuration parameters) throws Exception {
                        super.open(parameters);
                        this.getRuntimeContext().addAccumulator("imIntCounter", numLines);
                    }
                    @Override
                    public void close() throws Exception {
                        super.close();
                    }
                    public void flatMap(String s, Collector<WordWithCount> collector) throws Exception {
                        for (String word : s.split("\\s")) {
                            numLines.add(1);
                            collector.collect(new WordWithCount(word, 1L));
                        }
                    }
                })
                .groupBy("word")
                .reduce(new ReduceFunction<WordWithCount>() {
                    public WordWithCount reduce(WordWithCount wordWithCount, WordWithCount t1) throws Exception {
                        return new WordWithCount(wordWithCount.word, wordWithCount.count+t1.count);
                    }
                });
        wordCounts.writeAsText("/Users/ivanl001/Desktop/bigData/00-data/output/batch/out");
        //wordCounts.print();
        JobExecutionResult result = env.execute();
        System.out.println(result.getAccumulatorResult("imIntCounter").toString());
    }
    // Data type for words with count
    public static class WordWithCount {
        //注意如果是私有变量必须要有get和set方法，要不然flink没法用这个模型
        public String word;
        public long count;
        public WordWithCount() {}
        public WordWithCount(String word, long count) {
            this.word = word;
            this.count = count;
        }
        @Override
        public String toString() {
            return word + " : " + count;
        }
    }
}
```



##### 3.2, 自定义累加器：

* 实现Accumulator或者SimpleAccumulator 





