[TOC]

1，环境调整和输入法配置

2，生活记录整理

3,  集群启动

4,  新人培训

5，熟悉数据结构

6，集群搭建需求调研

*　http://www.ha97.com/5673.html
*　https://blog.csdn.net/qq_36381640/article/details/85229649
*　https://blog.csdn.net/u011594486/article/details/77507591

```shell
#
数量： 最小集群主机数要求应为3台
内存： 虚拟机最低单机运行的内存不能低于 10 GB

# 历史使用过的机器配置
50CPU 256G +　ｎＴ磁盘空间

# 调研建议使用机器配置
主节点： CPU：双核及以上，内存：32GB 	及以上
从节点： CPU: 双核及以上，内存：16GB 及以上
硬盘： 应根据数据的使用来计算

# 系统
centos7
jdk1.8

# 网络
Hadoop网络要求：

1.所有的Hadoop服务器节点应该是独有的网络，而不存在跟其他应用程序的节点共享网络I/O的情况。
2.每个服务器应该都配置静态IP。如果配置了动态IP，在机器重启或者DNS租约过期时，机器的IP地址会改变，这将导致Hadoop服务故障。
3.专用TOR交换机。
4.专用的核心交换刀片或者核心交换机。
5.尽量保证应用服务器与Hadoop“近”一些。
6.CDH只支持IPv4，不支持IPv6
7.机架之间的网络连接速度应该足够快。
8.确保网络接口对于集群中的所有节点应该是一致的。（比如MTU设置应该一样）
9.关闭所有节点的Huge Page compaction
10.确保集群中的所有网络连接都会被监控，比如冲突和丢包问题。以方便后期进行排障。


# 官方推荐
记住, 在思想上，Hadoop 体系设计为用于一种并行环境。

  如果你希望Hadoop集群扩展到20台机器以上，那么我们推荐最初配置的集群应分布在两个机架，而且每个机架都有一个位于机架顶部的10G的以太网交 换。当这个集群跨越多个机架的时候，你将需要添加核心交换机使用40G的以太网来连接位于机架顶部的交换机。两个逻辑上分离的机架可以让维护团队更好地理 解机架内部和机架间通信对网络需求。

Hadoop集群安装好后，维护团队就可以开始确定工作负载，并准备对这些工作负载进行基准测试以确定硬件瓶颈。经过一段时间的基准测试和监视，维护团队 将会明白如何配置添加的机器。异构的Hadoop集群是很常见的，尤其是在集群中用户机器的容量和数量不断增长的时候更常见-因此为你的工作负载所配置的 “不理想”开始时的那组机器不是在浪费时间。Cloudera管理器提供了允许分组管理不同硬件配置的模板，通过这些模板你就可以简单地管理异构集群了。

 下面是针对不同的工作负载所采用对应的各种硬件配置的列表，包括我们最初推荐的“负载均衡”的配置：

轻量处理方式的配置(1U的机器）:两个16核的CPU，24-64GB的内存以及8张硬盘（每张1TB或者2TB)。

负载均衡方式的配置(1U的机器）:两个16核的CPU，48-128GB的内存以及由主板控制器直接连接的12-16张硬盘（每张1TB或者2TB)。通常在一个2U的柜子里使用2个主板和24张硬盘实现相互备份。

超大存储方式的配置(2U的机器）:两个16核的CPU，48-96GB的内存以及16-26张硬盘（每张2TB-4TB)。这种配置在多个节点/机架失效时会产生大量的网络流量。

强力运算方式的配置(2U的机器）:两个16核的CPU，64-512GB的内存以及4-8张硬盘（每张1TB或者2TB)。
（注意Cloudera期望你配置它可以使用的2×8,2×10和2×12核心CPU的配置。)



# hbase
由于垃圾回收器（GC）的超时，HBase 的用户应该留意堆的大小的限制。别的JVM列存储也面临这个问题。因此，我们推荐每一个区域服务器的堆最大不超过16GB。HBase不需要太多别的资源 而运行于Hadoop之上，但是维护一个实时的SLAs，你应该使用多个调度器，比如使用fair and capacity 调度器，并协同Linux Cgroups使用。

# Impala
Impala使用内存以完成其大多数的功能，在默认的配置下，将最多使用80％的可用RAM资源，所以我们推荐，最少每一个节点使用96GB的RAM。与MapReduce一起使用Impala的用户，可以参考我们的建议 － “Configuring Impala and MapReduce for Multi-tenant Performance.” 也可以为Impala指定特定进程所需的内存或者特定查询所需的内存。
```



```shell
其他配置参考 ：

样例一：

One name node: 2-hex cores CPU, 24 GB RAM, 100 GB Storage
Two data nodes: each with 2 cores CPU, 8 GB RAM, 100 GB Storage


样例二：
DataNodes:
12-24 1-4TB hard disks in a JBOD (Just a Bunch Of Disks) configuration
2 quad-/hex-/octo-core CPUs, running at least 2-2.5GHz
64-512GB of RAM
Bonded Gigabit Ethernet or 10Gigabit Ethernet (the more storage density, the higher the network throughput needed)


NameNode:
4–6 1TB hard disks in a JBOD configuration (1 for the OS, 2 for the FS image [RAID 1], 1 for Apache ZooKeeper, and 1 for Journal node)
2 quad-/hex-/octo-core CPUs, running at least 2-2.5GHz
64-128GB of RAM
Bonded Gigabit Ethernet or 10Gigabit Ethernet
```



## 5，熟悉数据结构



## 日报

```shell
20190910任务：
    1，测试数据库表结构熟悉
    	任务状态：进行中
    	任务进度：40%
    2, 虚拟机搭建测试服务器
    	任务状态：完成
20190911任务：
	1，测试数据库表结构熟悉
	2，数据库拉取工具cannal(实时拉取)和datax(离线拉取)的调研
	3，大数据全文搜索框架es的调研
```



