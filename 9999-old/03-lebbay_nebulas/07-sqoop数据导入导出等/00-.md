```shell

report-system.cbb0nles4v8i.us-east-1.rds.amazonaws.com:3306
admin
Jde27dePlWbx32aMTr

# 显示数据库
sqoop-list-databases --connect jdbc:mysql://report-system.cbb0nles4v8i.us-east-1.rds.amazonaws.com:3306/ --username admin --password Jde27dePlWbx32aMTr

# 显示数据库中的表
sqoop-list-tables --connect jdbc:mysql://report-system.cbb0nles4v8i.us-east-1.rds.amazonaws.com:3306/azazie_report --username admin --password Jde27dePlWbx32aMTr


# 导入到HDFS指定目录, \表示和下面的是一行，转义而已
# --split-by代表用来切片的字段，-m为1的话其实不用指定分片字段
# -m代表指定maptask，如果有多个maptask，那会生成多个文件，没有reduce阶段哦
/opt/cloudera/parcels/CDH/bin/sqoop import \
--connect jdbc:mysql://report-system.cbb0nles4v8i.us-east-1.rds.amazonaws.com:3306/azazie_report \
--username admin \
--password Jde27dePlWbx32aMTr \
--target-dir /sqoop/database/report/stock \
--fields-terminated-by ',' \
--table stock  \
--split-by id \
--m 1


/opt/cloudera/parcels/CDH/bin/sqoop import \
--connect jdbc:mysql://report-system.cbb0nles4v8i.us-east-1.rds.amazonaws.com:3306/azazie_report \
--username admin \
--password Jde27dePlWbx32aMTr \
--table stock  \
--split-by id  \
--hive-import  \
--hive-database 'report'  \
--fields-terminated-by ','  \
--m 1

#!/bin/bash
# 导入限定1: 限定条件限定
/opt/cloudera/parcels/CDH/bin/sqoop import \
--connect jdbc:mysql://azaziedbslave.cbb0nles4v8i.us-east-1.rds.amazonaws.com:3306/azazie \
--username aztech1 \
--password 8m4UquCBkNYn \
--target-dir /user/hive/warehouse/azazie.db/order_info \
--table ods_order_info  \
--split-by id  \
--hive-import  \
--hive-database 'azazie'  \
--fields-terminated-by ','  \
--where "(pay_time>='2020-01-03' and pay_time<'2020-01-04') and (order_time>='2020-01-03' and order_time<'2020-01-04')" \
--hive-partition-key 'report_date' \
--hive-partition-value '2020-01-03' \
--m 1
```

